{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "8qWQy_PMQ-t8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X20ERLBTSVZk",
        "outputId": "a5a1e82c-9962-4de1-8ff5-eb43260caafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.169.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-api-python-client\n",
        "!pip install networkx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import json\n",
        "import networkx as nx\n",
        "import os\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "YRIhYu2gEB57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "QH7HWMPRQ4y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_videos(query, max_results):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_results:\n",
        "        remaining = max_results - len(videos)\n",
        "        fetch_count = min(50, remaining)\n",
        "\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part='snippet',\n",
        "            type='video',\n",
        "            maxResults=fetch_count,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response['items']:\n",
        "            video_info = {\n",
        "                'id': item['id']['videoId'],\n",
        "                'title': item['snippet']['title'],\n",
        "                'publishedAt': item['snippet']['publishedAt'],\n",
        "                'channelId': item['snippet']['channelId'],\n",
        "                'author': item['snippet']['channelTitle']\n",
        "            }\n",
        "            videos.append(video_info)\n",
        "\n",
        "        next_page_token = search_response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return videos[:max_results]"
      ],
      "metadata": {
        "id": "nudrFx_sSiuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comments(video_id):\n",
        "    comments = []\n",
        "\n",
        "    def get_page(page_token=None):\n",
        "        request = youtube.commentThreads().list(\n",
        "            part='snippet,replies',\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=page_token,\n",
        "            textFormat='plainText'\n",
        "        )\n",
        "        return request.execute()\n",
        "\n",
        "    response = get_page()\n",
        "    while response:\n",
        "        for item in response['items']:\n",
        "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "            comment_data = {\n",
        "                'commentId': item['id'],\n",
        "                'text': top_comment['textDisplay'],\n",
        "                'author': top_comment['authorDisplayName'],\n",
        "                'publishedAt': top_comment['publishedAt'],\n",
        "                'replies': []\n",
        "            }\n",
        "\n",
        "            if 'replies' in item:\n",
        "                for reply in item['replies']['comments']:\n",
        "                    reply_snippet = reply['snippet']\n",
        "                    comment_data['replies'].append({\n",
        "                        'commentId': reply['id'],\n",
        "                        'text': reply_snippet['textDisplay'],\n",
        "                        'author': reply_snippet['authorDisplayName'],\n",
        "                        'publishedAt': reply_snippet['publishedAt'],\n",
        "                    })\n",
        "\n",
        "            comments.append(comment_data)\n",
        "\n",
        "        if 'nextPageToken' in response:\n",
        "            response = get_page(response['nextPageToken'])\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return comments\n"
      ],
      "metadata": {
        "id": "RuAeG30oSme0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_comment_tree(comments):\n",
        "    for c in comments:\n",
        "        print(f\"{c['author']} said at {c['publishedAt']}: {c['text']}\")\n",
        "        for r in c['replies']:\n",
        "            print(f\"  â†³ {r['author']} replied at {r['publishedAt']}: {r['text']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dcCbG5K9SsjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_comment_tree_as_json(comments, filename='comment_tree.json'):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(comments, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "MMX-D67xT4_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_replies_recursively(parent_id):\n",
        "    replies = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        request = youtube.comments().list(\n",
        "            part='snippet',\n",
        "            parentId=parent_id,\n",
        "            textFormat='plainText',\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response.get('items', []):\n",
        "            reply_snippet = item['snippet']\n",
        "            reply_data = {\n",
        "                'commentId': item['id'],\n",
        "                'text': reply_snippet['textDisplay'],\n",
        "                'author': reply_snippet['authorDisplayName'],\n",
        "                'publishedAt': reply_snippet['publishedAt'],\n",
        "                'replies': fetch_replies_recursively(item['id'])  # ðŸ§  recursion here!\n",
        "            }\n",
        "            replies.append(reply_data)\n",
        "\n",
        "        next_page_token = response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return replies\n"
      ],
      "metadata": {
        "id": "Ht2abwlXUloE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "def get_full_comment_tree(video_id):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    try:\n",
        "      while True:\n",
        "          request = youtube.commentThreads().list(\n",
        "              part='snippet',\n",
        "              videoId=video_id,\n",
        "              maxResults=100,\n",
        "              textFormat='plainText',\n",
        "              pageToken=next_page_token\n",
        "          )\n",
        "          response = request.execute()\n",
        "\n",
        "          for item in response.get('items', []):\n",
        "              top_comment_snippet = item['snippet']['topLevelComment']['snippet']\n",
        "              comment_data = {\n",
        "                  'commentId': item['id'],\n",
        "                  'text': top_comment_snippet['textDisplay'],\n",
        "                  'author': top_comment_snippet['authorDisplayName'],\n",
        "                  'publishedAt': top_comment_snippet['publishedAt'],\n",
        "                  'replies': fetch_replies_recursively(item['id'])\n",
        "              }\n",
        "              comments.append(comment_data)\n",
        "\n",
        "          next_page_token = response.get('nextPageToken')\n",
        "          if not next_page_token:\n",
        "              break\n",
        "\n",
        "    except HttpError as e:\n",
        "      error_reason = e.error_details[0].get(\"reason\", \"\") if e.error_details else \"\"\n",
        "      if error_reason == \"commentsDisabled\":\n",
        "          print(f\"Skipping video '{video_id}' â€” comments are disabled.\")\n",
        "      else:\n",
        "          print(f\"HTTP error occurred for video '{video_id}': {e}\")\n",
        "    return comments\n"
      ],
      "metadata": {
        "id": "dJpZGiI0V-N-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_depth(comments): #Not necessary depth is fixed at 2 in Youtube\n",
        "    if not comments:\n",
        "        return 0\n",
        "    return 1 + max((get_max_depth(comment.get('replies', [])) for comment in comments), default=0)\n"
      ],
      "metadata": {
        "id": "7pZitt3fWaZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "i7soOCj5_eTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY=''\n",
        "youtube = build('youtube', 'v3', developerKey=API_KEY)"
      ],
      "metadata": {
        "id": "e-uhQdMg7Pxq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query"
      ],
      "metadata": {
        "id": "fvLcFHeHQzPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query='parking bonaire valencia'\n",
        "os.makedirs(query, exist_ok=True)\n",
        "results_number=100"
      ],
      "metadata": {
        "id": "AbvjKmReENWT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos = search_videos('parking bonaire valencia', max_results=results_number)\n",
        "with open(query+'/videos_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(videos, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "r78ejpbBE9Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comment Trees"
      ],
      "metadata": {
        "id": "OwTYgZDTQpIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query='parking bonaire valencia'\n",
        "results_number=100\n",
        "\n",
        "with open(query+'/videos_data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "video_ids = [video['id'] for video in data]"
      ],
      "metadata": {
        "id": "FQCbxI-FnbU4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = os.path.join(query,'comment_trees')\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "json_files = [f for f in os.listdir(output_folder) if f.endswith('.json')]\n",
        "json_ids = {os.path.splitext(f)[0] for f in json_files}\n",
        "remaining_ids = [id_ for id_ in video_ids if id_ not in json_ids]\n",
        "\n",
        "print(len(video_ids),video_ids)\n",
        "print(len(json_ids),json_ids)\n",
        "print(len(remaining_ids), remaining_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc6wRgITol9R",
        "outputId": "075260e5-5071-4499-8564-ffa4353e1987"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 ['p2JaYHVnJiA', '6BMKx4sQ2o8', '3nrMNFtgKOo', 'LRtSPJi4Byk', 'u4Tnc5Z3u-Y', '5Ml8j7L_4c8', 'IpnKlUAzkoQ', 'dP-fovsQUYc', '-1xTSrm3p_0', 'OaseDDoc4ZQ', 'JRheS8fDrWM', 'dgSM5iDeHzU', 'bLx6AErC2nQ', 'nfVyFlqr3Go', 'SSZfvpx4grQ', 'ivnS8ZE3AO4', 'YnDCuawdEDM', 'Fy6GnmVzChM', 'zzIzMlbZu3s', 'sKRRt855AwI', 'aPouPRfDNA4', 'rYEJUMFt0BI', '1oz3ndF76WA', 'mOnaqqncMx4', '-tzCe4R5beg', 'UozH6vKj_GU', 'LS1jakQlCQ8', 'qk9IjnHodmM', 'Jo6ZOV8NS3g', 'CHBrNCP1BIs', 'MZDtnUxTbUI', 'NOXfLILDlB0', 'n5PM0OWhHNY', 'FwRsnP2BEdI', 'IByXtKzZusE', '7cEX45Mstak', 'gx-46d9NpNY', '0_o_p_GjFD0', 'eSalGRSXG4Q', 'OaKyLCJ75WU', 's21f1Q_kyA0', 'd7Ybk89ZKVo', 'J1NGIwkRApA', '9l7rUQtW-9Y', '574Q_dyRNZM', 'krYkQ9Z6A1Y', 'GkRmMcMk8U0', 'aUZBuQJ3pKQ', 'BaCW1W2cU5g', 'DWvjDi1eDNQ', 'aUZBuQJ3pKQ', '3eC9MIYGsbI', 'UC0fAr1OGHk', 'Y51xfO35ENk', 'GosHhphzLTo', 'SzuClHgS0Ow', '9bcJt3mRCIo', 'py4Y0ac-0ks', 'cbYVznlbWqk', 'SJ576J3uULc', 'ta1W5lScquI', 'jVQ9PY6nmKc', 'mLqFm4gIuAc', '8nWSEWgaGlA', '6psSXZ0vReA', 'QKauHor_2Jw', 'yXKblUPp3mU', 'JLWNaCWNJqE', 'ZGJpAM7fL3Q', 'hn9IpLpbkTA', 'LZwOY25pfoA', 'sxSJ-sWWlBw', '2esskDJ8E_o', 'BU-5kuF0y-E', 'L5lXyh98Itg', 'iUcnGXnQS6s', 'EXEDXMjE6-U', 'GBCNh5W229Y', 'SzB0kxkr5gU', 'lbXx9zAhg48', 'PoNSUbTCXE4', 'An2n874v-W8', 'T7D-LlLFpDg', 'kWHWO4NCWac', 'IqAPFfIXTVQ', 'gPYtAfkl324', 'Oi0G7Lk80xE', 'xQv4BeP6kmY', 'sVjQzk7UpgA', 'HUtqIb7fc94', '84NorZ4KFiw', '5OGUwBDItGc', 'MhPmA78ysVU', 'ricGhCxX69s', 'IFZ2EZcLsEg', 'Npv7b2RRET0', 'Bp6UDhqeEe4', 'vSI2Frq5aoA', 'fZlY_3NK45Y', 'fha4HWsflnM']\n",
            "85 {'ivnS8ZE3AO4', 'YnDCuawdEDM', 'NOXfLILDlB0', 'gPYtAfkl324', 'Y51xfO35ENk', 'LRtSPJi4Byk', '3nrMNFtgKOo', 'u4Tnc5Z3u-Y', 'py4Y0ac-0ks', 'OaseDDoc4ZQ', 'bLx6AErC2nQ', 'eSalGRSXG4Q', '3eC9MIYGsbI', 'LS1jakQlCQ8', 'JRheS8fDrWM', 'FwRsnP2BEdI', '6psSXZ0vReA', 'vSI2Frq5aoA', '1oz3ndF76WA', 'Jo6ZOV8NS3g', 'SJ576J3uULc', '84NorZ4KFiw', '-tzCe4R5beg', 'aUZBuQJ3pKQ', '0_o_p_GjFD0', 'L5lXyh98Itg', 's21f1Q_kyA0', 'iUcnGXnQS6s', 'p2JaYHVnJiA', 'SSZfvpx4grQ', 'T7D-LlLFpDg', 'LZwOY25pfoA', '9l7rUQtW-9Y', '8nWSEWgaGlA', 'JLWNaCWNJqE', 'An2n874v-W8', 'nfVyFlqr3Go', '5OGUwBDItGc', 'GBCNh5W229Y', 'aPouPRfDNA4', 'GosHhphzLTo', 'Fy6GnmVzChM', 'DWvjDi1eDNQ', 'CHBrNCP1BIs', 'n5PM0OWhHNY', '6BMKx4sQ2o8', '5Ml8j7L_4c8', 'mOnaqqncMx4', 'MZDtnUxTbUI', 'mLqFm4gIuAc', 'SzuClHgS0Ow', 'ta1W5lScquI', 'ricGhCxX69s', '9bcJt3mRCIo', 'qk9IjnHodmM', 'IqAPFfIXTVQ', 'Bp6UDhqeEe4', 'OaKyLCJ75WU', '574Q_dyRNZM', 'UC0fAr1OGHk', 'BaCW1W2cU5g', 'sKRRt855AwI', 'QKauHor_2Jw', 'HUtqIb7fc94', 'MhPmA78ysVU', 'GkRmMcMk8U0', 'J1NGIwkRApA', 'Npv7b2RRET0', 'krYkQ9Z6A1Y', '-1xTSrm3p_0', 'yXKblUPp3mU', 'fZlY_3NK45Y', '7cEX45Mstak', 'lbXx9zAhg48', 'ZGJpAM7fL3Q', 'dgSM5iDeHzU', 'UozH6vKj_GU', 'BU-5kuF0y-E', 'd7Ybk89ZKVo', 'rYEJUMFt0BI', 'PoNSUbTCXE4', 'SzB0kxkr5gU', 'IpnKlUAzkoQ', 'kWHWO4NCWac', 'dP-fovsQUYc'}\n",
            "14 ['zzIzMlbZu3s', 'IByXtKzZusE', 'gx-46d9NpNY', 'cbYVznlbWqk', 'jVQ9PY6nmKc', 'hn9IpLpbkTA', 'sxSJ-sWWlBw', '2esskDJ8E_o', 'EXEDXMjE6-U', 'Oi0G7Lk80xE', 'xQv4BeP6kmY', 'sVjQzk7UpgA', 'IFZ2EZcLsEg', 'fha4HWsflnM']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for element in remaining_ids:\n",
        "  os.makedirs(output_folder, exist_ok=True)\n",
        "  comment_tree =get_full_comment_tree(element)\n",
        "  if comment_tree:\n",
        "    save_comment_tree_as_json(comment_tree, filename=output_folder+'/'+element+'.json')\n",
        "    print(element)\n",
        "  else:\n",
        "    print('empty: '+element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhwKwwPcFO8X",
        "outputId": "83aa5330-3102-4b88-a442-f988c0aacfc4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty: zzIzMlbZu3s\n",
            "empty: IByXtKzZusE\n",
            "Skipping video 'gx-46d9NpNY' â€” comments are disabled.\n",
            "empty: gx-46d9NpNY\n",
            "empty: cbYVznlbWqk\n",
            "empty: jVQ9PY6nmKc\n",
            "empty: hn9IpLpbkTA\n",
            "empty: sxSJ-sWWlBw\n",
            "empty: 2esskDJ8E_o\n",
            "empty: EXEDXMjE6-U\n",
            "empty: Oi0G7Lk80xE\n",
            "empty: xQv4BeP6kmY\n",
            "empty: sVjQzk7UpgA\n",
            "empty: IFZ2EZcLsEg\n",
            "empty: fha4HWsflnM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your JSON files\n",
        "directory = output_folder\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.json'):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        try:\n",
        "            with open(filepath, 'r') as f:\n",
        "                content = f.read().strip()\n",
        "                if not content or json.loads(content) in ({}, []):\n",
        "                    os.remove(filepath)\n",
        "                    print(f\"Deleted empty/blank JSON file: {filename}\")\n",
        "        except (json.JSONDecodeError, OSError):\n",
        "            print(f\"Skipped unreadable or malformed file: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk5HpvkJ2Jum",
        "outputId": "ef1c170f-91fb-4c11-a6e8-1d2d706e4d31"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted empty/blank JSON file: sVjQzk7UpgA.json\n",
            "Deleted empty/blank JSON file: ricGhCxX69s.json\n",
            "Deleted empty/blank JSON file: hn9IpLpbkTA.json\n",
            "Deleted empty/blank JSON file: jVQ9PY6nmKc.json\n",
            "Deleted empty/blank JSON file: zzIzMlbZu3s.json\n",
            "Deleted empty/blank JSON file: kWHWO4NCWac.json\n",
            "Deleted empty/blank JSON file: vSI2Frq5aoA.json\n",
            "Deleted empty/blank JSON file: GBCNh5W229Y.json\n",
            "Deleted empty/blank JSON file: 84NorZ4KFiw.json\n",
            "Deleted empty/blank JSON file: iUcnGXnQS6s.json\n",
            "Deleted empty/blank JSON file: IFZ2EZcLsEg.json\n",
            "Deleted empty/blank JSON file: IqAPFfIXTVQ.json\n",
            "Deleted empty/blank JSON file: sxSJ-sWWlBw.json\n",
            "Deleted empty/blank JSON file: Bp6UDhqeEe4.json\n",
            "Deleted empty/blank JSON file: Oi0G7Lk80xE.json\n",
            "Deleted empty/blank JSON file: gx-46d9NpNY.json\n",
            "Deleted empty/blank JSON file: T7D-LlLFpDg.json\n",
            "Deleted empty/blank JSON file: fha4HWsflnM.json\n",
            "Deleted empty/blank JSON file: PoNSUbTCXE4.json\n",
            "Deleted empty/blank JSON file: 5OGUwBDItGc.json\n",
            "Deleted empty/blank JSON file: An2n874v-W8.json\n",
            "Deleted empty/blank JSON file: fZlY_3NK45Y.json\n",
            "Deleted empty/blank JSON file: gPYtAfkl324.json\n",
            "Deleted empty/blank JSON file: EXEDXMjE6-U.json\n",
            "Deleted empty/blank JSON file: SzB0kxkr5gU.json\n",
            "Deleted empty/blank JSON file: IByXtKzZusE.json\n",
            "Deleted empty/blank JSON file: cbYVznlbWqk.json\n",
            "Deleted empty/blank JSON file: 2esskDJ8E_o.json\n",
            "Deleted empty/blank JSON file: xQv4BeP6kmY.json\n",
            "Deleted empty/blank JSON file: lbXx9zAhg48.json\n",
            "Deleted empty/blank JSON file: HUtqIb7fc94.json\n",
            "Deleted empty/blank JSON file: MhPmA78ysVU.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs"
      ],
      "metadata": {
        "id": "oIdqNCMmQgyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Undirected Bipartite graph generation where all authors are connected to the\n",
        "# videos they have commented or responded on\n",
        "B = nx.Graph()\n",
        "\n",
        "authors = set()\n",
        "edges =set()\n",
        "input_path=os.path.join(query,'comment_trees')\n",
        "\n",
        "for filename in os.listdir(input_path):\n",
        "  if filename.endswith('.json'):\n",
        "    video_id=filename[-16:-5]\n",
        "    file_path = os.path.join(input_path, filename)\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "      try:\n",
        "        comments = json.load(file)\n",
        "        for comment in comments:\n",
        "          authors.add(comment['author'])\n",
        "          edges.add((video_id,comment['author']))\n",
        "\n",
        "          for reply in comment['replies']:\n",
        "            authors.add(reply['author'])\n",
        "            edges.add((video_id,reply['author']))\n",
        "      except json.JSONDecodeError:\n",
        "                    print(f\"Error decoding JSON in file {filename}\")\n",
        "\n",
        "B.add_nodes_from(video_ids, bipartite=0)\n",
        "B.add_nodes_from(authors, bipartite=1)\n",
        "\n",
        "B.add_edges_from(edges)\n",
        "nx.write_graphml(B, query+\"/graph_1.graphml\")"
      ],
      "metadata": {
        "id": "nKhUv55yKfsK"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directed bipartite graph generation where all authors are connected to the\n",
        "# videos they on and to the other users they have responded to with strength\n",
        "# equal to the number of comments/responses to that particular video/author\n",
        "G = nx.DiGraph()\n",
        "\n",
        "authors = set()\n",
        "video_ids = set()\n",
        "\n",
        "edge_type1_counts = defaultdict(int)\n",
        "edge_type2_counts = defaultdict(int)\n",
        "edge_type3_counts = defaultdict(int)\n",
        "\n",
        "input_path = os.path.join(query, 'comment_trees')\n",
        "\n",
        "for filename in os.listdir(input_path):\n",
        "    if filename.endswith('.json'):\n",
        "        video_id = filename[-16:-5]\n",
        "        video_ids.add(video_id)\n",
        "        file_path = os.path.join(input_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            try:\n",
        "                comments = json.load(file)\n",
        "                for comment in comments:\n",
        "                    author = comment['author']\n",
        "                    authors.add(author)\n",
        "\n",
        "                    edge_type1_counts[(author, video_id)] += 1\n",
        "\n",
        "                    for reply in comment.get('replies', []):\n",
        "                        replier = reply['author']\n",
        "                        authors.add(replier)\n",
        "\n",
        "                        edge_type2_counts[(replier, video_id)] += 1\n",
        "\n",
        "                        edge_type3_counts[(replier, author)] += 1\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error decoding JSON in file {filename}\")\n",
        "\n",
        "# Add nodes\n",
        "G.add_nodes_from(video_ids, type='video')\n",
        "G.add_nodes_from(authors, type='author')\n",
        "\n",
        "# Add Type 1 edges (non-directed, but we add them as edges with attribute 'type')\n",
        "for (author, video), count in edge_type1_counts.items():\n",
        "    G.add_edge(author, video, type='Comment', strength=count)\n",
        "\n",
        "# Add Type 2 edges (directed)\n",
        "for (replier, commenter), count in edge_type2_counts.items():\n",
        "    G.add_edge(replier, commenter, type='Reply', strength=count)\n",
        "\n",
        "\n",
        "# Add Type 3 edges (directed)\n",
        "#for (replier, video), count in edge_type3_counts.items():\n",
        "#    G.add_edge(replier, video, type='type3', strength=count)\n",
        "\n",
        "nx.write_graphml(G, query+\"/graph_2.graphml\")"
      ],
      "metadata": {
        "id": "zRDmicGZP5mI"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download"
      ],
      "metadata": {
        "id": "Yod5in63QVvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compress and download query\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "shutil.make_archive(query, 'zip', query)\n",
        "files.download(query+'.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cqzFEZ4iMgCL",
        "outputId": "b965ba11-f770-4983-e7aa-c52cfe02deec"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7ecbf748-ab97-4231-b995-1284990d0b32\", \"parking bonaire valencia.zip\", 4370302)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}